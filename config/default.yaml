project_name: "coconut-code-llm"
experiment_name: "swe-smith-qwen2.5-coder-7B-Instruct"
output_dir: "./outputs_qwen2.5-coder-7B-Instruct"
seed: 42

model:
  name: "Qwen/Qwen2.5-Coder-7B-Instruct"
  dtype: "bfloat16"
  trust_remote_code: true
  
  # Quantization
  use_quantization: false
  quantization:
    load_in_4bit: true
    bnb_4bit_quant_type: "nf4"
    bnb_4bit_compute_dtype: "bfloat16"
    bnb_4bit_use_double_quant: true

  # LoRA
  use_lora: true
  lora:
    r: 8
    lora_alpha: 16
    target_modules: ["q_proj", "v_proj", "k_proj", "o_proj", "gate_proj", "up_proj", "down_proj"]
    lora_dropout: 0.05

  # resume_from_checkpoint: "outputs_qwen2.5-7B-Instruct/final_model"
  gradient_checkpointing: true

data:
  dataset_name: "SWE-bench/SWE-smith"
  split: "train"
  max_seq_length: 4096
  max_prompt_length: 4096
  batch_size: 2
  num_workers: 4
  gradient_accumulation_steps: 1
  cache_dir: "./data_cache"

training:
  # COCONUT stages
  num_stages: 3
  epoch_per_stage: 1
  
  # Stage ratios: какую часть CoT шагов заменить на латентные
  # stage 0: 0% - только language tokens
  # stage 1: 33% - 1/3 латентных, 2/3 language
  # stage 2: 66% - 2/3 латентных, 1/3 language
  # stage 3: 100% - все латентные
  
  continuous_thought_steps: 2  # Кол-во латентных шагов
  
  warmup_steps: 200
  num_training_steps: 10000
  logging_steps: 10
  save_steps: 500
  eval_steps: 1000

optimizer:
  name: "adamw"
  lr: 1e-5
  weight_decay: 0.01
  betas: [0.9, 0.999]
  eps: 1e-8
  max_grad_norm: 10.0
  warmup_steps: 200

monitoring:
  use_wandb: false
  wandb_project: "coconut-code"
  wandb_entity: null
  log_model: false

checkpoint:
  save_strategy: "steps"
  save_steps: 500
  resume_from_checkpoint: null
  load_best_model_at_end: true